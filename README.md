# ğŸ“˜ Emotion System

A real-time multimodal emotion detection system that recognizes human emotions by analyzing both **visual input (facial expressions)** and **audio input (speech)**. Combines camera and microphone signals for robust emotion predictions.

---

## ğŸš€ Features

- Real-time webcam face emotion recognition  
- Continuous audio recording and speech emotion analysis  
- Confidence-aware fusion of visual and audio predictions  
- Temporal smoothing of final emotion outputs  

---

## ğŸ“ Project Structure
emotion-system/
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ visual_model.py
â”‚ â”œâ”€â”€ audio_model.py
â”‚ â””â”€â”€ fusion_model.py
â”œâ”€â”€ streaming/
â”‚ â”œâ”€â”€ camera.py
â”‚ â””â”€â”€ audio_stream.py
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ entrophy.py
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸ“¦ Installation

1. **Clone the repo**  
   ```bash
    git clone https://github.com/chamindusenehas/emotion-system.git
    cd emotion-system

2. **Create a virtual environment (optional)**
    ```bash
        python -m venv venv
        venv\Scripts\activate  # Windows
        source venv/bin/activate  # macOS/Linux

3. **Install dependencies**
    ```bash
        pip install -r requirements.txt

# ğŸ”§ How It Works

**ğŸ¥ Visual Emotion Detection**

- Captures frames from webcam

- Detects faces

- Classifies facial emotion

**ğŸ¤ Audio Emotion Detection**

- Continuously records audio

- Detects speech segments

- Maps audio emotion labels to visual emotion space

**ğŸ¤ Fusion Logic**

- Combines visual and audio predictions

- Weights each modality based on confidence

- Produces a smoothed final emotion

## ğŸ“Œ Running the System

Run the main script:

    python main.py


Example console output:

        Visual: neutral (0.82), Audio: happy (0.59), Fused: happy (0.72)

Press q to exit.